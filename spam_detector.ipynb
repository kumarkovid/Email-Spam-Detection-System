{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from matplotlib import pyplot\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import time\n",
    "wn=nltk.WordNetLemmatizer()\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\",100)\n",
    "data=pd.read_csv(\"C:/Users/HP/Downloads/SMSSpamCollection_LinkedIn.tsv\",sep=\"\\t\",header=None,names=[\"ham_spam\", \"body_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "\n",
    "def punctuation_perc (text):     #Write for one line and usee apply to use it recursively\n",
    "    count=sum([1 for char in text if char in string.punctuation])\n",
    "    perc_punc=round(count / (len(text)- text.count(\" \")), 3)*100\n",
    "    return perc_punc\n",
    "data['punc_%age'] = data['body_text'].apply(lambda x: punctuation_perc (x))\n",
    "data['Len_body_text'] = data['body_text'].apply(lambda x:len(x) - x.count(\" \"))\n",
    "# Cleaning not required for spam detection\n",
    "\n",
    "stopwords=nltk.corpus.stopwords.words('english')\n",
    "ps=nltk.PorterStemmer()\n",
    "def Clean_text(text):\n",
    "    text = \"\".join([char.lower() for char in text if char not in string.punctuation])\n",
    "    tokens=re.split('\\W+',text)\n",
    "    text=[ps.stem(text) for char in tokens if char not in stopwords]\n",
    "    return text\n",
    "\n",
    "#np.sum(X_features,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_features_tfidf, data['ham_spam'],test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf Vectorizer\n",
    "tfidf_vect=TfidfVectorizer(analyzer=Clean_text)  #analyzer=Clean_text\n",
    "x_tfidf=tfidf_vect.fit_transform(data['body_text'])\n",
    "x_features_tfidf=pd.concat([data['Len_body_text'],data['punc_%age'],pd.DataFrame(x_tfidf.toarray())],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97127469, 0.97845601, 0.97127469, 0.96495957, 0.97214735])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_jobs=-1)\n",
    "k_fold=KFold(n_splits=5)\n",
    "cross_val_score(rf,x_features_tfidf,data['ham_spam'],cv=k_fold,scoring='accuracy',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.058121783365796285, 'Len_body_text'),\n",
       " (0.04513345679124285, 1827),\n",
       " (0.027100726897952808, 7983),\n",
       " (0.023143159947188498, 2065),\n",
       " (0.021312117485355792, 7312),\n",
       " (0.019431758058350762, 5116),\n",
       " (0.016891758207703823, 8593),\n",
       " (0.01674604386869628, 6110),\n",
       " (0.01533831936635971, 616),\n",
       " (0.014903426798839237, 8520)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=50, max_depth=20, n_jobs= -1)\n",
    "rf_model=rf.fit(x_train,y_train)\n",
    "sorted(zip(rf_model.feature_importances_,x_train.columns),reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.674 0.958\n"
     ]
    }
   ],
   "source": [
    "y_pred=rf_model.predict(x_test)\n",
    "precision,recall,fscore,support = score(y_test,y_pred,pos_label='spam',average='binary')\n",
    "print(round(precision, 3),round(recall,3),round((y_pred==y_test).sum()/len(y_pred),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 100/ Depth: 60----- Precision=0.987 / Recall=0.848 / Accuracy=0.979\n",
      "Est: 100/ Depth: 90----- Precision=0.987 / Recall=0.854 / Accuracy=0.98\n",
      "Est: 100/ Depth: None----- Precision=0.987 / Recall=0.86 / Accuracy=0.981\n",
      "Est: 150/ Depth: 60----- Precision=0.987 / Recall=0.848 / Accuracy=0.979\n",
      "Est: 150/ Depth: 90----- Precision=0.987 / Recall=0.848 / Accuracy=0.979\n",
      "Est: 150/ Depth: None----- Precision=0.987 / Recall=0.854 / Accuracy=0.98\n",
      "Est: 200/ Depth: 60----- Precision=0.987 / Recall=0.837 / Accuracy=0.978\n",
      "Est: 200/ Depth: 90----- Precision=0.987 / Recall=0.865 / Accuracy=0.981\n",
      "Est: 200/ Depth: None----- Precision=0.987 / Recall=0.848 / Accuracy=0.979\n"
     ]
    }
   ],
   "source": [
    "# Manual RandomForestClassifier\n",
    "def train_RF(n_est,depth):\n",
    "    rf=RandomForestClassifier(n_estimators=n_est,max_depth=depth,n_jobs=-1)\n",
    "    rf_model=rf.fit(x_train,y_train)\n",
    "    y_pred=rf_model.predict(x_test)\n",
    "    precision,recall,f_score,support=score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "    print(\"Est: {}/ Depth: {}----- Precision={} / Recall={} / Accuracy={}\".format(n_est, depth, round(precision,3),\n",
    "                                                    round(recall,3),round((y_pred==y_test).sum()/len(y_pred),3)))\n",
    "    \n",
    "#Precision: percentage of mails in spam were really a spam  \n",
    "#Recall: Percentage of spams that went to spam folder\n",
    "#Accuracy: correctness of detecting spam or ham -- not a good indicator as this will be 80(% of ham in dataset) by default\n",
    "\n",
    "for n_est in [50,100,150,200]:\n",
    "    for depth in [20,30,60, 90, None]:\n",
    "        train_RF(n_est,depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 50/ Depth: 3/ LR: 0.01 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 50/ Depth: 3/ LR: 0.1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 50/ Depth: 3/ LR: 1 ----- Precision=0.888 / Recall=0.848 / Accuracy=0.967\n",
      "Est: 50/ Depth: 7/ LR: 0.01 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 50/ Depth: 7/ LR: 0.1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 50/ Depth: 7/ LR: 1 ----- Precision=0.89 / Recall=0.86 / Accuracy=0.968\n",
      "Est: 50/ Depth: 11/ LR: 0.01 ----- Precision=0.888 / Recall=0.848 / Accuracy=0.967\n",
      "Est: 50/ Depth: 11/ LR: 0.1 ----- Precision=0.89 / Recall=0.86 / Accuracy=0.968\n",
      "Est: 50/ Depth: 11/ LR: 1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 50/ Depth: 15/ LR: 0.01 ----- Precision=0.888 / Recall=0.848 / Accuracy=0.967\n",
      "Est: 50/ Depth: 15/ LR: 0.1 ----- Precision=0.883 / Recall=0.848 / Accuracy=0.966\n",
      "Est: 50/ Depth: 15/ LR: 1 ----- Precision=0.888 / Recall=0.848 / Accuracy=0.967\n",
      "Est: 100/ Depth: 3/ LR: 0.01 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 100/ Depth: 3/ LR: 0.1 ----- Precision=0.888 / Recall=0.848 / Accuracy=0.967\n",
      "Est: 100/ Depth: 3/ LR: 1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 100/ Depth: 7/ LR: 0.01 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 100/ Depth: 7/ LR: 0.1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 100/ Depth: 7/ LR: 1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 100/ Depth: 11/ LR: 0.01 ----- Precision=0.89 / Recall=0.865 / Accuracy=0.969\n",
      "Est: 100/ Depth: 11/ LR: 0.1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 100/ Depth: 11/ LR: 1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 100/ Depth: 15/ LR: 0.01 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 100/ Depth: 15/ LR: 0.1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 100/ Depth: 15/ LR: 1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 150/ Depth: 3/ LR: 0.01 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 150/ Depth: 3/ LR: 0.1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 150/ Depth: 3/ LR: 1 ----- Precision=0.888 / Recall=0.848 / Accuracy=0.967\n",
      "Est: 150/ Depth: 7/ LR: 0.01 ----- Precision=0.89 / Recall=0.865 / Accuracy=0.969\n",
      "Est: 150/ Depth: 7/ LR: 0.1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 150/ Depth: 7/ LR: 1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 150/ Depth: 11/ LR: 0.01 ----- Precision=0.89 / Recall=0.86 / Accuracy=0.968\n",
      "Est: 150/ Depth: 11/ LR: 0.1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 150/ Depth: 11/ LR: 1 ----- Precision=0.89 / Recall=0.86 / Accuracy=0.968\n",
      "Est: 150/ Depth: 15/ LR: 0.01 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 150/ Depth: 15/ LR: 0.1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 150/ Depth: 15/ LR: 1 ----- Precision=0.89 / Recall=0.86 / Accuracy=0.968\n",
      "Est: 200/ Depth: 3/ LR: 0.01 ----- Precision=0.89 / Recall=0.865 / Accuracy=0.969\n",
      "Est: 200/ Depth: 3/ LR: 0.1 ----- Precision=0.891 / Recall=0.871 / Accuracy=0.97\n",
      "Est: 200/ Depth: 3/ LR: 1 ----- Precision=0.89 / Recall=0.86 / Accuracy=0.968\n",
      "Est: 200/ Depth: 7/ LR: 0.01 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 200/ Depth: 7/ LR: 0.1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 200/ Depth: 7/ LR: 1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 200/ Depth: 11/ LR: 0.01 ----- Precision=0.888 / Recall=0.848 / Accuracy=0.967\n",
      "Est: 200/ Depth: 11/ LR: 0.1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 200/ Depth: 11/ LR: 1 ----- Precision=0.889 / Recall=0.854 / Accuracy=0.968\n",
      "Est: 200/ Depth: 15/ LR: 0.01 ----- Precision=0.89 / Recall=0.86 / Accuracy=0.968\n",
      "Est: 200/ Depth: 15/ LR: 0.1 ----- Precision=0.89 / Recall=0.865 / Accuracy=0.969\n",
      "Est: 200/ Depth: 15/ LR: 1 ----- Precision=0.888 / Recall=0.848 / Accuracy=0.967\n"
     ]
    }
   ],
   "source": [
    "# Manual GradientBoostingClassifier\n",
    "def train_GB(est,max_depth,lr):\n",
    "    gb=GradientBoostingClassifier(n_estimators=est,max_depth=depth) #DEFINING\n",
    "    gb_model=gb.fit(x_train,y_train)  #FITTING\n",
    "    y_pred=gb_model.predict(x_test)   #PREDICT\n",
    "    precision, recall, f_score, support=score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "    print(\"Est: {}/ Depth: {}/ LR: {} ----- Precision={} / Recall={} / Accuracy={}\".format(n_est, max_depth, lr, \n",
    "                                                                                round(precision,3),round(recall,3),\n",
    "                                                                                round((y_pred==y_test).sum()/len(y_pred),3)))   \n",
    "for n_est in[50,100,150,200]:\n",
    "        for max_depth in [3,7,11,15]:\n",
    "            for lr in [0.01,0.1,1]:\n",
    "                train_GB(n_est, max_depth, lr)   \n",
    "                \n",
    "#Some models will provide poor results and common reasons are less depth, learning rate(lr)=0.01, low estimators\n",
    "#Some models will provide good results and common reasons are more depth, learning rate(lr)=0.1, very high estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier with grid search cv on count_features\n",
    "rf=RandomForestClassifier()\n",
    "param={\"n_estimators\" : [50,100,150,200],\n",
    "       \"max_depth\" : [20,30,60,90],\n",
    "      }\n",
    "gs = GridSearchCV(rf,param,cv=4)#cv=5 creates 5 subsets\n",
    "gs_fit=gs.fit(count_features_tfidf,data[\"body_text\"])\n",
    "results=pd.DataFrame(gs_fit.cv_results).sort_values(\"mean_test_score\",ascending=False)[:5]#prints results of all combinations\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoostingClassifier with grid search cv\n",
    "gb=GradientBoostingClassifier()\n",
    "param={\"n_estimators\" : [100,150,200],\n",
    "       \"max_depth\" : [3,7,11,15],\n",
    "       \"learning_rate\" : [0.01,0.1,1]\n",
    "      }\n",
    "clf = GridSearchCV(rf,param,cv=5)#cv=5 creates 5 subsets\n",
    "cv_fit=clf.fit(x_features_tfidf,data[\"body_text\"])\n",
    "results=pd.DataFrame(cv_fit.cv_results).sort_values(\"mean_test_score\",ascending=False)[:5] #prints results of all combinations\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 6.002 / Predict time: 0.25 ------ Precision=0.987 / Recall=0.837 / Accuracy=0.978\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier with best values from searches\n",
    "rf=RandomForestClassifier(n_estimators=150,max_depth=None,n_jobs=-1)\n",
    "\n",
    "start=time.time()\n",
    "rf_model=rf.fit(x_train,y_train)\n",
    "end=time.time()\n",
    "fit_time=end-start\n",
    "\n",
    "start=time.time()\n",
    "y_pred=rf_model.predict(x_test)\n",
    "end=time.time()\n",
    "pred_time=end-start\n",
    "\n",
    "precision, recall, f_score, support=score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "print(\"Fit time: {} / Predict time: {} ------ Precision={} / Recall={} / Accuracy={}\".format\n",
    "                                                    (round(fit_time,3), round(pred_time,3), round(precision,3),\n",
    "                                                    round(recall,3),round((y_pred==y_test).sum()/len(y_pred),3)))\n",
    "\n",
    "#Precision: percentage of mails in spam were really a spam  \n",
    "#Recall: Percentage of spams that went to spam folder\n",
    "#Accuracy: correctness of detecting spam or ham -- not a good indicator as this will be 80(% of ham in dataset) by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 311.83546209335327 / Predict time: 0.2500030994415283 ----- Precision=0.939 / Recall=0.871 / Accuracy=0.976\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostClassifier with best values from searches\n",
    "gb=GradientBoostingClassifier(n_estimators=150,max_depth=11)\n",
    "start=time.time()\n",
    "gb_model=gb.fit(x_train,y_train)\n",
    "end=time.time()\n",
    "fit_time=end-start\n",
    "\n",
    "start=time.time()\n",
    "y_pred=gb_model.predict(x_test)\n",
    "end=time.time()\n",
    "pred_time=end-start\n",
    "\n",
    "precision, recall, f_score, support=score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "print(\"Fit time: {} / Predict time: {} ----- Precision={} / Recall={} / Accuracy={}\".format\n",
    "                                                    (fit_time, pred_time, round(precision,3),\n",
    "                                                    round(recall,3),round((y_pred==y_test).sum()/len(y_pred),3)))\n",
    "\n",
    "#Precision: percentage of mails in spam were really a spam  \n",
    "#Recall: Percentage of spams that went to spam folder\n",
    "#Accuracy: correctness of detecting spam or ham -- not a good indicator as this will be 80(% of ham in dataset) by default"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
